{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 11: Time-Varying Parameter VAR (Part 2)\n",
    "# TVP-VAR Models and Applications\n",
    "\n",
    "## Summer School: Time Series Methods for Finance and Economics\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "1. Specify full TVP-VAR models with stochastic volatility\n",
    "2. Understand the computational challenges of TVP-VAR estimation\n",
    "3. Implement simplified TVP-VAR models\n",
    "4. Calculate time-varying impulse response functions\n",
    "5. Analyze dynamic spillovers and connectedness\n",
    "6. Apply TVP-VAR to financial contagion\n",
    "7. Interpret structural change in multivariate relationships\n",
    "8. Integrate time series methods for complete analysis\n",
    "\n",
    "### Prerequisites\n",
    "- Session 8: Vector Autoregression (VAR)\n",
    "- Session 10: TVP Models and Kalman Filter\n",
    "- Understanding of MCMC methods (helpful but not required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.linalg import block_diag, cholesky, inv\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.precision', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TVP-VAR Model Specification\n",
    "\n",
    "### 1.1 Full TVP-VAR Model\n",
    "\n",
    "**Primiceri (2005) specification**:\n",
    "\n",
    "$$\\mathbf{y}_t = \\mathbf{X}_t \\boldsymbol{\\beta}_t + \\mathbf{A}_t^{-1} \\boldsymbol{\\Sigma}_t \\boldsymbol{\\epsilon}_t, \\quad \\boldsymbol{\\epsilon}_t \\sim N(\\mathbf{0}, \\mathbf{I})$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{y}_t$: $N \\times 1$ vector of variables\n",
    "- $\\mathbf{X}_t$: $1 \\times K$ matrix of lags (RHS variables)\n",
    "- $\\boldsymbol{\\beta}_t$: $K \\times N$ matrix of time-varying coefficients\n",
    "- $\\mathbf{A}_t$: Lower triangular matrix (contemporaneous relations)\n",
    "- $\\boldsymbol{\\Sigma}_t$: Diagonal matrix of stochastic volatilities\n",
    "\n",
    "### 1.2 Time-Varying Parameters\n",
    "\n",
    "**VAR coefficients** (random walk):\n",
    "$$\\boldsymbol{\\beta}_t = \\boldsymbol{\\beta}_{t-1} + \\boldsymbol{\\nu}_t, \\quad \\boldsymbol{\\nu}_t \\sim N(\\mathbf{0}, \\mathbf{Q})$$\n",
    "\n",
    "**Contemporaneous relations**:\n",
    "$$\\mathbf{a}_t = \\mathbf{a}_{t-1} + \\boldsymbol{\\zeta}_t, \\quad \\boldsymbol{\\zeta}_t \\sim N(\\mathbf{0}, \\mathbf{S})$$\n",
    "\n",
    "where $\\mathbf{a}_t$ stacks lower triangular elements of $\\mathbf{A}_t^{-1}$.\n",
    "\n",
    "**Stochastic volatility** (log variance):\n",
    "$$\\log \\sigma_{i,t}^2 = \\log \\sigma_{i,t-1}^2 + \\eta_{i,t}, \\quad \\eta_{i,t} \\sim N(0, w_i)$$\n",
    "\n",
    "### 1.3 Interpretation\n",
    "\n",
    "**Three sources of variation**:\n",
    "1. **$\\boldsymbol{\\beta}_t$**: Changing VAR coefficients (lag responses)\n",
    "2. **$\\mathbf{A}_t$**: Changing contemporaneous relations\n",
    "3. **$\\boldsymbol{\\Sigma}_t$**: Changing volatilities (uncertainty)\n",
    "\n",
    "**Economic meaning**:\n",
    "- Monetary policy transmission can change\n",
    "- Shock propagation varies over time\n",
    "- Forecast uncertainty evolves\n",
    "- Crisis periods have different dynamics\n",
    "\n",
    "### 1.4 Computational Challenges\n",
    "\n",
    "**High dimensionality**:\n",
    "- For $N=3$, $p=2$: 18 VAR coefficients per equation\n",
    "- Plus contemporaneous and volatility parameters\n",
    "- Total: 100+ time-varying parameters\n",
    "\n",
    "**Estimation**:\n",
    "- Maximum likelihood infeasible\n",
    "- Bayesian MCMC methods (Gibbs sampling)\n",
    "- Requires priors on $\\mathbf{Q}$, $\\mathbf{S}$, $\\mathbf{W}$\n",
    "- Computationally intensive\n",
    "\n",
    "**Simplifications for this session**:\n",
    "- Focus on time-varying $\\boldsymbol{\\beta}_t$\n",
    "- Constant volatility or simple structure\n",
    "- Rolling VAR as approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Download multivariate data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Downloading Multivariate Financial Data\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get multiple asset classes for spillover analysis\n",
    "tickers = ['SPY', 'TLT', 'GLD']  # Stocks, Bonds, Gold\n",
    "data = yf.download(tickers, start='2008-01-01', end='2024-01-01', progress=False)['Close']\n",
    "data.columns = ['Stocks', 'Bonds', 'Gold']\n",
    "data = data.dropna()\n",
    "\n",
    "# Calculate returns\n",
    "returns = data.pct_change().dropna() * 100\n",
    "\n",
    "print(f\"\\nData period: {returns.index[0].date()} to {returns.index[-1].date()}\")\n",
    "print(f\"Observations: {len(returns)}\")\n",
    "print(f\"\\nAssets:\")\n",
    "print(\"  • SPY: S&P 500 ETF (stocks)\")\n",
    "print(\"  • TLT: 20+ Year Treasury Bond ETF\")\n",
    "print(\"  • GLD: Gold ETF\")\n",
    "print(\"\\nThis period includes:\")\n",
    "print(\"  • Financial crisis (2008-2009)\")\n",
    "print(\"  • European debt crisis (2011-2012)\")\n",
    "print(\"  • COVID-19 pandemic (2020)\")\n",
    "print(\"  • Post-pandemic recovery (2021-2023)\")\n",
    "\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(returns.describe().round(4))\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(returns.corr().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 14))\n",
    "\n",
    "# Returns\n",
    "returns.plot(ax=axes[0], linewidth=1, alpha=0.7)\n",
    "axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[0].set_title('Daily Returns: Stocks, Bonds, Gold', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Return (%)', fontsize=11)\n",
    "axes[0].legend(loc='best', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add crisis periods\n",
    "crisis_periods = [\n",
    "    ('2008-09-01', '2009-03-31', 'Financial Crisis', 'red'),\n",
    "    ('2020-02-01', '2020-04-30', 'COVID-19', 'orange')\n",
    "]\n",
    "for start, end, label, color in crisis_periods:\n",
    "    axes[0].axvspan(pd.Timestamp(start), pd.Timestamp(end), \n",
    "                    alpha=0.2, color=color)\n",
    "\n",
    "# Rolling volatility (60-day)\n",
    "rolling_vol = returns.rolling(window=60).std() * np.sqrt(252)\n",
    "rolling_vol.plot(ax=axes[1], linewidth=1.5, alpha=0.7)\n",
    "axes[1].set_title('Rolling Volatility (60-day, Annualized)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Volatility (%)', fontsize=11)\n",
    "axes[1].legend(loc='best', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling correlations\n",
    "rolling_corr_sb = returns['Stocks'].rolling(window=120).corr(returns['Bonds'])\n",
    "rolling_corr_sg = returns['Stocks'].rolling(window=120).corr(returns['Gold'])\n",
    "rolling_corr_bg = returns['Bonds'].rolling(window=120).corr(returns['Gold'])\n",
    "\n",
    "axes[2].plot(returns.index, rolling_corr_sb, linewidth=2, label='Stocks-Bonds', alpha=0.7)\n",
    "axes[2].plot(returns.index, rolling_corr_sg, linewidth=2, label='Stocks-Gold', alpha=0.7)\n",
    "axes[2].plot(returns.index, rolling_corr_bg, linewidth=2, label='Bonds-Gold', alpha=0.7)\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[2].set_title('Rolling Correlations (120-day)', fontsize=13, fontweight='bold')\n",
    "axes[2].set_ylabel('Correlation', fontsize=11)\n",
    "axes[2].set_ylim(-1, 1)\n",
    "axes[2].legend(loc='best', fontsize=10)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative returns\n",
    "cum_returns = (1 + returns/100).cumprod()\n",
    "cum_returns.plot(ax=axes[3], linewidth=2, alpha=0.7)\n",
    "axes[3].set_title('Cumulative Returns', fontsize=13, fontweight='bold')\n",
    "axes[3].set_xlabel('Date', fontsize=11)\n",
    "axes[3].set_ylabel('Cumulative Return', fontsize=11)\n",
    "axes[3].legend(loc='best', fontsize=10)\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"• Volatility spikes during crises\")\n",
    "print(\"• Stock-bond correlation changes sign over time\")\n",
    "print(\"• Gold serves as safe haven (negative correlation with stocks)\")\n",
    "print(\"• Relationships are clearly time-varying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simplified TVP-VAR: Rolling Window Approach\n",
    "\n",
    "### 2.1 Rolling Window VAR\n",
    "\n",
    "**Simple approximation** to full TVP-VAR:\n",
    "- Estimate VAR over moving window\n",
    "- Window size $w$ (e.g., 250 days ≈ 1 year)\n",
    "- At time $t$: use data $[t-w+1, t]$\n",
    "\n",
    "**Pros**:\n",
    "- Easy to implement\n",
    "- No hyperparameters to tune\n",
    "- Standard VAR software\n",
    "\n",
    "**Cons**:\n",
    "- Discrete jumps in estimates\n",
    "- Arbitrary window choice\n",
    "- Less efficient than Kalman\n",
    "\n",
    "### 2.2 Time-Varying Impulse Responses\n",
    "\n",
    "**At each time $t$**:\n",
    "1. Estimate VAR on window ending at $t$\n",
    "2. Calculate IRFs from estimated coefficients\n",
    "3. Store IRFs for horizon $h$\n",
    "\n",
    "**Result**: $\\text{IRF}_{ij}(h, t)$ - response of $i$ to shock in $j$ at horizon $h$ and time $t$.\n",
    "\n",
    "### 2.3 Interpretation\n",
    "\n",
    "**How shock transmission changes**:\n",
    "- Crisis vs normal times\n",
    "- Policy regime changes\n",
    "- Market integration effects\n",
    "- Structural breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement rolling window VAR\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Rolling Window VAR Estimation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "window = 252  # 1 year\n",
    "max_lags = 5\n",
    "\n",
    "# Storage for results\n",
    "rolling_dates = []\n",
    "rolling_coefs = []  # Store coefficient matrices\n",
    "rolling_residuals = []\n",
    "\n",
    "print(f\"\\nWindow size: {window} days\")\n",
    "print(f\"Maximum lags tested: {max_lags}\")\n",
    "print(f\"\\nEstimating...\")\n",
    "\n",
    "for i in range(window, len(returns)):\n",
    "    if i % 500 == 0:\n",
    "        print(f\"  Progress: {i}/{len(returns)}\")\n",
    "    \n",
    "    # Extract window\n",
    "    window_data = returns.iloc[i-window:i]\n",
    "    \n",
    "    try:\n",
    "        # Fit VAR\n",
    "        model = VAR(window_data)\n",
    "        # Select lag order\n",
    "        lag_order = model.select_order(maxlags=max_lags)\n",
    "        selected_lag = lag_order.bic\n",
    "        \n",
    "        # Estimate\n",
    "        fitted = model.fit(selected_lag)\n",
    "        \n",
    "        # Store results\n",
    "        rolling_dates.append(returns.index[i])\n",
    "        rolling_coefs.append(fitted.params)  # Coefficient matrix\n",
    "        rolling_residuals.append(fitted.resid)\n",
    "        \n",
    "    except:\n",
    "        # Skip if estimation fails\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Completed: {len(rolling_dates)} windows estimated\")\n",
    "print(f\"  Start date: {rolling_dates[0].date()}\")\n",
    "print(f\"  End date: {rolling_dates[-1].date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Extract specific coefficients over time\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Time-Varying VAR Coefficients\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Focus on first lag coefficients\n",
    "# Structure: [const, L1.Stocks, L1.Bonds, L1.Gold] for each equation\n",
    "\n",
    "# Extract coefficients for Stocks equation\n",
    "stocks_on_stocks_l1 = [coef.iloc[1, 0] for coef in rolling_coefs]  # Stocks on Stocks(-1)\n",
    "stocks_on_bonds_l1 = [coef.iloc[2, 0] for coef in rolling_coefs]   # Stocks on Bonds(-1)\n",
    "stocks_on_gold_l1 = [coef.iloc[3, 0] for coef in rolling_coefs]    # Stocks on Gold(-1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "coef_df = pd.DataFrame({\n",
    "    'Stocks_on_Stocks': stocks_on_stocks_l1,\n",
    "    'Stocks_on_Bonds': stocks_on_bonds_l1,\n",
    "    'Stocks_on_Gold': stocks_on_gold_l1\n",
    "}, index=rolling_dates)\n",
    "\n",
    "print(\"\\nStocks Equation - First Lag Coefficients:\")\n",
    "print(coef_df.describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize time-varying coefficients\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Stocks on Stocks(-1)\n",
    "coef_df['Stocks_on_Stocks'].plot(ax=axes[0], linewidth=2, color='blue', alpha=0.7)\n",
    "axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0].axhline(y=coef_df['Stocks_on_Stocks'].mean(), color='red', \n",
    "               linestyle='--', linewidth=2, alpha=0.7,\n",
    "               label=f\"Mean: {coef_df['Stocks_on_Stocks'].mean():.3f}\")\n",
    "axes[0].set_title('TVP: Stocks on Stocks(-1)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Coefficient', fontsize=11)\n",
    "axes[0].legend(loc='best', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add crisis periods\n",
    "for start, end, label, color in crisis_periods:\n",
    "    axes[0].axvspan(pd.Timestamp(start), pd.Timestamp(end), \n",
    "                    alpha=0.15, color=color)\n",
    "\n",
    "# Stocks on Bonds(-1)\n",
    "coef_df['Stocks_on_Bonds'].plot(ax=axes[1], linewidth=2, color='green', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1].axhline(y=coef_df['Stocks_on_Bonds'].mean(), color='red',\n",
    "               linestyle='--', linewidth=2, alpha=0.7,\n",
    "               label=f\"Mean: {coef_df['Stocks_on_Bonds'].mean():.3f}\")\n",
    "axes[1].set_title('TVP: Stocks on Bonds(-1)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Coefficient', fontsize=11)\n",
    "axes[1].legend(loc='best', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "for start, end, label, color in crisis_periods:\n",
    "    axes[1].axvspan(pd.Timestamp(start), pd.Timestamp(end),\n",
    "                    alpha=0.15, color=color)\n",
    "\n",
    "# Stocks on Gold(-1)\n",
    "coef_df['Stocks_on_Gold'].plot(ax=axes[2], linewidth=2, color='orange', alpha=0.7)\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[2].axhline(y=coef_df['Stocks_on_Gold'].mean(), color='red',\n",
    "               linestyle='--', linewidth=2, alpha=0.7,\n",
    "               label=f\"Mean: {coef_df['Stocks_on_Gold'].mean():.3f}\")\n",
    "axes[2].set_title('TVP: Stocks on Gold(-1)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Date', fontsize=11)\n",
    "axes[2].set_ylabel('Coefficient', fontsize=11)\n",
    "axes[2].legend(loc='best', fontsize=10)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "for start, end, label, color in crisis_periods:\n",
    "    axes[2].axvspan(pd.Timestamp(start), pd.Timestamp(end),\n",
    "                    alpha=0.15, color=color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"• Autoregressive coefficient varies substantially\")\n",
    "print(\"• Bond-stock relationship changes sign over time\")\n",
    "print(\"• Gold coefficient more stable but with variation\")\n",
    "print(\"• Crisis periods show different dynamics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time-Varying Impulse Response Functions\n",
    "\n",
    "### 3.1 Computing Time-Varying IRFs\n",
    "\n",
    "**For each time $t$**:\n",
    "1. Use VAR coefficients $\\Phi_t^{(1)}, \\ldots, \\Phi_t^{(p)}$\n",
    "2. Compute MA representation: $\\Psi_0, \\Psi_1, \\ldots, \\Psi_h$\n",
    "3. Apply Cholesky orthogonalization\n",
    "4. Extract IRF for each variable pair\n",
    "\n",
    "**Result**: $\\text{IRF}_{ij}(h, t)$\n",
    "\n",
    "### 3.2 Visualization Strategies\n",
    "\n",
    "**Heatmaps**: Show IRF evolution over time and horizon\n",
    "\n",
    "**3D surfaces**: Time × Horizon × Response\n",
    "\n",
    "**Time slices**: IRFs at specific dates (crisis vs normal)\n",
    "\n",
    "**Horizon slices**: How immediate vs delayed responses change\n",
    "\n",
    "### 3.3 Economic Interpretation\n",
    "\n",
    "**Flight to quality**:\n",
    "- During crisis: Negative stock shock → positive bond response\n",
    "- Normal times: Weaker or opposite effect\n",
    "\n",
    "**Safe haven behavior**:\n",
    "- Gold response to stock shocks\n",
    "- Time-varying hedge properties\n",
    "\n",
    "**Contagion**:\n",
    "- Spillovers stronger during stress\n",
    "- Market integration effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate time-varying IRFs\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Time-Varying Impulse Response Functions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Parameters\n",
    "irf_horizon = 10\n",
    "sample_every = 20  # Sample every N periods to reduce computation\n",
    "\n",
    "# Storage for IRFs\n",
    "# Structure: time × horizon × response_var × shock_var\n",
    "n_times = len(range(0, len(rolling_dates), sample_every))\n",
    "n_vars = len(returns.columns)\n",
    "tv_irfs = np.zeros((n_times, irf_horizon+1, n_vars, n_vars))\n",
    "sampled_dates = []\n",
    "\n",
    "print(f\"\\nComputing IRFs:\")\n",
    "print(f\"  Horizon: {irf_horizon} periods\")\n",
    "print(f\"  Sampling: every {sample_every} periods\")\n",
    "print(f\"  Total IRFs: {n_times}\")\n",
    "\n",
    "for idx, i in enumerate(range(0, len(rolling_dates), sample_every)):\n",
    "    if idx % 20 == 0:\n",
    "        print(f\"  Progress: {idx}/{n_times}\")\n",
    "    \n",
    "    # Get window data\n",
    "    window_end = rolling_dates[i]\n",
    "    window_start_idx = returns.index.get_loc(window_end) - window + 1\n",
    "    window_data = returns.iloc[window_start_idx:window_start_idx+window]\n",
    "    \n",
    "    try:\n",
    "        # Fit VAR\n",
    "        model = VAR(window_data)\n",
    "        lag_order = model.select_order(maxlags=max_lags)\n",
    "        fitted = model.fit(lag_order.bic)\n",
    "        \n",
    "        # Calculate IRF\n",
    "        irf = fitted.irf(irf_horizon)\n",
    "        \n",
    "        # Store orthogonalized IRFs\n",
    "        tv_irfs[idx, :, :, :] = irf.orth_irfs\n",
    "        sampled_dates.append(window_end)\n",
    "        \n",
    "    except:\n",
    "        # If estimation fails, use NaN\n",
    "        tv_irfs[idx, :, :, :] = np.nan\n",
    "        sampled_dates.append(window_end)\n",
    "\n",
    "print(f\"\\n✓ IRF calculation complete\")\n",
    "print(f\"  Computed {n_times} time-varying IRFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize time-varying IRFs: Stock shock → Bond response\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Time-Varying IRF: Stock Shock → Bond Response\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract: Bonds (index 1) response to Stocks (index 0) shock\n",
    "irf_stocks_to_bonds = tv_irfs[:, :, 1, 0]  # [time, horizon]\n",
    "\n",
    "# Create heatmap\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "# Heatmap\n",
    "im = axes[0].imshow(irf_stocks_to_bonds.T, aspect='auto', cmap='RdBu_r',\n",
    "                    origin='lower', extent=[0, len(sampled_dates), 0, irf_horizon],\n",
    "                    vmin=-0.1, vmax=0.1)\n",
    "axes[0].set_title('Time-Varying IRF: Bond Response to Stock Shock',\n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Time', fontsize=11)\n",
    "axes[0].set_ylabel('Horizon (days)', fontsize=11)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=axes[0])\n",
    "cbar.set_label('Response', fontsize=11)\n",
    "\n",
    "# Set x-axis to dates (sample for readability)\n",
    "n_ticks = 6\n",
    "tick_indices = np.linspace(0, len(sampled_dates)-1, n_ticks, dtype=int)\n",
    "axes[0].set_xticks(tick_indices)\n",
    "axes[0].set_xticklabels([sampled_dates[i].strftime('%Y-%m') for i in tick_indices],\n",
    "                        rotation=45)\n",
    "\n",
    "# Plot impact response over time (horizon 0)\n",
    "axes[1].plot(sampled_dates, irf_stocks_to_bonds[:, 0], linewidth=2,\n",
    "            color='blue', alpha=0.7, label='Impact (h=0)')\n",
    "axes[1].plot(sampled_dates, irf_stocks_to_bonds[:, 1], linewidth=2,\n",
    "            color='green', alpha=0.7, label='1-day (h=1)')\n",
    "axes[1].plot(sampled_dates, irf_stocks_to_bonds[:, 5], linewidth=2,\n",
    "            color='orange', alpha=0.7, label='5-day (h=5)')\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Bond Response to Stock Shock at Different Horizons',\n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].set_ylabel('Response', fontsize=11)\n",
    "axes[1].legend(loc='best', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"• During crises: Stock shock → positive bond response (flight to safety)\")\n",
    "print(\"• Normal times: Weaker or opposite relationship\")\n",
    "print(\"• Response magnitude and persistence vary over time\")\n",
    "print(\"• Heatmap shows evolution of entire IRF profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Compare IRFs: Crisis vs Normal Times\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IRF Comparison: Crisis vs Normal Times\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select specific dates\n",
    "# Crisis: Financial crisis (2008-10)\n",
    "# Normal: Pre-crisis (2007-06)\n",
    "\n",
    "# Find closest dates in sampled_dates\n",
    "crisis_date = pd.Timestamp('2008-10-15')\n",
    "normal_date = pd.Timestamp('2007-06-15')\n",
    "\n",
    "def find_closest_idx(target_date, date_list):\n",
    "    return min(range(len(date_list)), \n",
    "               key=lambda i: abs(date_list[i] - target_date))\n",
    "\n",
    "crisis_idx = find_closest_idx(crisis_date, sampled_dates)\n",
    "normal_idx = find_closest_idx(normal_date, sampled_dates)\n",
    "\n",
    "print(f\"\\nSelected dates:\")\n",
    "print(f\"  Normal: {sampled_dates[normal_idx].date()}\")\n",
    "print(f\"  Crisis: {sampled_dates[crisis_idx].date()}\")\n",
    "\n",
    "# Extract IRFs\n",
    "var_names = returns.columns\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 14))\n",
    "\n",
    "for i, resp_var in enumerate(var_names):\n",
    "    for j, shock_var in enumerate(var_names):\n",
    "        ax = axes[i, j]\n",
    "        \n",
    "        # Normal times IRF\n",
    "        irf_normal = tv_irfs[normal_idx, :, i, j]\n",
    "        # Crisis times IRF\n",
    "        irf_crisis = tv_irfs[crisis_idx, :, i, j]\n",
    "        \n",
    "        horizons = np.arange(irf_horizon+1)\n",
    "        ax.plot(horizons, irf_normal, 'b-', linewidth=2, \n",
    "               label='Normal', marker='o', markersize=4)\n",
    "        ax.plot(horizons, irf_crisis, 'r--', linewidth=2,\n",
    "               label='Crisis', marker='s', markersize=4)\n",
    "        ax.axhline(y=0, color='black', linestyle=':', alpha=0.5)\n",
    "        \n",
    "        if i == 0 and j == 0:\n",
    "            ax.legend(loc='best', fontsize=9)\n",
    "        \n",
    "        ax.set_title(f'{resp_var} ← {shock_var}', fontsize=10, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        if i == 2:\n",
    "            ax.set_xlabel('Horizon', fontsize=9)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel('Response', fontsize=9)\n",
    "\n",
    "plt.suptitle('Impulse Response Functions: Crisis vs Normal Times',\n",
    "            fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Differences:\")\n",
    "print(\"• Crisis: Larger immediate responses (higher volatility)\")\n",
    "print(\"• Crisis: Stronger cross-asset spillovers\")\n",
    "print(\"• Crisis: Stock-Bond negative correlation (flight to quality)\")\n",
    "print(\"• Normal: More muted responses, faster decay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dynamic Spillovers and Connectedness\n",
    "\n",
    "### 4.1 Diebold-Yilmaz Spillover Index\n",
    "\n",
    "**Forecast Error Variance Decomposition** at time $t$ and horizon $h$:\n",
    "\n",
    "$$\\theta_{ij}^{(h, t)} = \\frac{\\sum_{k=0}^{h-1} (\\mathbf{e}_i^\\top \\Psi_k^{(t)} \\mathbf{P}^{(t)} \\mathbf{e}_j)^2}{\\sum_{k=0}^{h-1} \\mathbf{e}_i^\\top \\Psi_k^{(t)} \\Sigma^{(t)} (\\Psi_k^{(t)})^\\top \\mathbf{e}_i}$$\n",
    "\n",
    "**Spillover index** at time $t$:\n",
    "\n",
    "$$S^{(t)} = \\frac{\\sum_{i \\neq j} \\theta_{ij}^{(h,t)}}{\\sum_{i,j} \\theta_{ij}^{(h,t)}} \\times 100\\%$$\n",
    "\n",
    "**Interpretation**:\n",
    "- Fraction of forecast error variance from other variables\n",
    "- $S^{(t)} = 0$: No spillovers (independent)\n",
    "- $S^{(t)} = 100$: All variation from others\n",
    "\n",
    "### 4.2 Directional Spillovers\n",
    "\n",
    "**From others to $i$**:\n",
    "$$S_{i \\leftarrow \\bullet}^{(t)} = \\frac{\\sum_{j \\neq i} \\theta_{ij}^{(h,t)}}{\\sum_j \\theta_{ij}^{(h,t)}} \\times 100\\%$$\n",
    "\n",
    "**From $i$ to others**:\n",
    "$$S_{i \\rightarrow \\bullet}^{(t)} = \\frac{\\sum_{j \\neq i} \\theta_{ji}^{(h,t)}}{\\sum_j \\theta_{ji}^{(h,t)}} \\times 100\\%$$\n",
    "\n",
    "**Net spillover**:\n",
    "$$S_i^{\\text{net}(t)} = S_{i \\rightarrow \\bullet}^{(t)} - S_{i \\leftarrow \\bullet}^{(t)}$$\n",
    "\n",
    "**Interpretation**:\n",
    "- $S_i^{\\text{net}} > 0$: Net transmitter of shocks\n",
    "- $S_i^{\\text{net}} < 0$: Net receiver of shocks\n",
    "\n",
    "### 4.3 Applications\n",
    "\n",
    "**Financial contagion**:\n",
    "- Spillovers increase during crises\n",
    "- Identify systemically important assets\n",
    "\n",
    "**Market integration**:\n",
    "- Rising spillovers over time\n",
    "- Globalization effects\n",
    "\n",
    "**Risk management**:\n",
    "- Time-varying diversification benefits\n",
    "- Dynamic hedging strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate spillover indices\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Dynamic Spillover Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def calculate_fevd(irf_orth, horizon):\n",
    "    \"\"\"\n",
    "    Calculate FEVD from orthogonalized IRFs.\n",
    "    irf_orth: [horizon+1, n_vars, n_vars]\n",
    "    Returns: [n_vars, n_vars] FEVD matrix\n",
    "    \"\"\"\n",
    "    n_vars = irf_orth.shape[1]\n",
    "    fevd = np.zeros((n_vars, n_vars))\n",
    "    \n",
    "    # Sum squared IRFs up to horizon\n",
    "    for i in range(n_vars):\n",
    "        mse_i = 0\n",
    "        for h in range(horizon+1):\n",
    "            mse_i += np.sum(irf_orth[h, i, :]**2)\n",
    "        \n",
    "        for j in range(n_vars):\n",
    "            contribution = 0\n",
    "            for h in range(horizon+1):\n",
    "                contribution += irf_orth[h, i, j]**2\n",
    "            \n",
    "            fevd[i, j] = contribution / mse_i if mse_i > 0 else 0\n",
    "    \n",
    "    return fevd\n",
    "\n",
    "def spillover_index(fevd):\n",
    "    \"\"\"\n",
    "    Calculate total spillover index from FEVD matrix.\n",
    "    \"\"\"\n",
    "    n = fevd.shape[0]\n",
    "    total = np.sum(fevd)\n",
    "    own = np.trace(fevd)\n",
    "    cross = total - own\n",
    "    return (cross / total * 100) if total > 0 else 0\n",
    "\n",
    "# Calculate spillovers at each time point\n",
    "horizon_fevd = 5  # Horizon for FEVD\n",
    "spillovers = []\n",
    "\n",
    "print(f\"\\nCalculating spillover indices (horizon={horizon_fevd})...\")\n",
    "\n",
    "for t in range(len(sampled_dates)):\n",
    "    fevd_t = calculate_fevd(tv_irfs[t], horizon_fevd)\n",
    "    spillover_t = spillover_index(fevd_t)\n",
    "    spillovers.append(spillover_t)\n",
    "\n",
    "spillovers = np.array(spillovers)\n",
    "\n",
    "print(f\"\\n✓ Spillover calculation complete\")\n",
    "print(f\"\\nSpillover Index Statistics:\")\n",
    "print(f\"  Mean: {np.nanmean(spillovers):.2f}%\")\n",
    "print(f\"  Std:  {np.nanstd(spillovers):.2f}%\")\n",
    "print(f\"  Min:  {np.nanmin(spillovers):.2f}%\")\n",
    "print(f\"  Max:  {np.nanmax(spillovers):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize spillover index over time\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Total spillover index\n",
    "axes[0].plot(sampled_dates, spillovers, linewidth=2, color='darkred', alpha=0.7)\n",
    "axes[0].axhline(y=np.nanmean(spillovers), color='blue', linestyle='--',\n",
    "               linewidth=2, label=f'Mean: {np.nanmean(spillovers):.1f}%')\n",
    "axes[0].set_title('Total Spillover Index Over Time', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Spillover Index (%)', fontsize=11)\n",
    "axes[0].legend(loc='best', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Shade crisis periods\n",
    "for start, end, label, color in crisis_periods:\n",
    "    axes[0].axvspan(pd.Timestamp(start), pd.Timestamp(end),\n",
    "                    alpha=0.2, color=color, label=label)\n",
    "\n",
    "# Add legend for crisis periods (only once)\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "# Remove duplicates\n",
    "by_label = dict(zip(labels, handles))\n",
    "axes[0].legend(by_label.values(), by_label.keys(), loc='best', fontsize=10)\n",
    "\n",
    "# Volatility for comparison\n",
    "avg_vol = returns.rolling(window=20).std().mean(axis=1) * np.sqrt(252)\n",
    "# Resample to match sampled_dates\n",
    "vol_sampled = [avg_vol.loc[:date].iloc[-1] if date in avg_vol.index \n",
    "               else np.nan for date in sampled_dates]\n",
    "\n",
    "axes[1].plot(sampled_dates, vol_sampled, linewidth=2, color='purple', alpha=0.7,\n",
    "            label='Average Volatility')\n",
    "axes[1].set_title('Average Volatility (for comparison)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].set_ylabel('Volatility (%)', fontsize=11)\n",
    "axes[1].legend(loc='best', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"• Spillovers spike during financial crises\")\n",
    "print(\"• Correlates with market volatility\")\n",
    "print(\"• Markets become more interconnected under stress\")\n",
    "print(\"• Diversification benefits reduced during crises\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Course Integration and Final Synthesis\n",
    "\n",
    "### 5.1 The Complete Time Series Toolkit\n",
    "\n",
    "**Sessions 1-4: Univariate Foundations**\n",
    "- Stationarity and unit roots\n",
    "- ARIMA models for forecasting\n",
    "- Exponential smoothing and decomposition\n",
    "- Model selection and diagnostics\n",
    "\n",
    "**Sessions 5-7: Volatility Modeling**\n",
    "- ARIMA extensions (SARIMA, ARIMAX)\n",
    "- ARCH/GARCH for time-varying volatility\n",
    "- Multivariate GARCH (DCC)\n",
    "- Risk measures (VaR, ES)\n",
    "\n",
    "**Sessions 8-9: Multivariate Models**\n",
    "- VAR for multiple time series\n",
    "- Granger causality and spillovers\n",
    "- Cointegration and VECM\n",
    "- Long-run equilibrium relationships\n",
    "\n",
    "**Sessions 10-11: Time-Varying Parameters**\n",
    "- State space models and Kalman filter\n",
    "- TVP regression and VAR\n",
    "- Dynamic impulse responses\n",
    "- Structural change and regime shifts\n",
    "\n",
    "### 5.2 Integrated Workflow Example\n",
    "\n",
    "**Research Question**: How do stock-bond correlations change over time?\n",
    "\n",
    "**Step 1: Data Preparation** (Sessions 1-2)\n",
    "- Test for stationarity\n",
    "- Transform if needed\n",
    "- Handle missing data\n",
    "- Outlier detection\n",
    "\n",
    "**Step 2: Univariate Analysis** (Sessions 3-4)\n",
    "- Model each series separately\n",
    "- Understand individual dynamics\n",
    "- Benchmark forecasts\n",
    "\n",
    "**Step 3: Volatility Analysis** (Sessions 6-7)\n",
    "- Estimate GARCH models\n",
    "- Time-varying volatility\n",
    "- Risk assessment\n",
    "\n",
    "**Step 4: Cointegration Test** (Session 9)\n",
    "- Are series cointegrated?\n",
    "- If yes: Use VECM\n",
    "- If no: Use VAR in differences\n",
    "\n",
    "**Step 5: Constant-Parameter VAR** (Session 8)\n",
    "- Baseline multivariate model\n",
    "- Static IRFs and FEVD\n",
    "- Test for parameter stability\n",
    "\n",
    "**Step 6: TVP-VAR** (Sessions 10-11)\n",
    "- Time-varying coefficients\n",
    "- Dynamic correlations\n",
    "- Crisis vs normal times\n",
    "- Spillover evolution\n",
    "\n",
    "**Step 7: Economic Interpretation**\n",
    "- Flight to quality during stress\n",
    "- Changing diversification benefits\n",
    "- Policy implications\n",
    "- Trading strategies\n",
    "\n",
    "### 5.3 Best Practices\n",
    "\n",
    "**Model Selection**:\n",
    "- Start simple, add complexity as needed\n",
    "- Use information criteria\n",
    "- Out-of-sample validation\n",
    "- Economic sensibility\n",
    "\n",
    "**Parameter Stability**:\n",
    "- Always test for breaks\n",
    "- Use recursive estimation\n",
    "- Consider TVP if unstable\n",
    "- Balance fit vs parsimony\n",
    "\n",
    "**Forecasting**:\n",
    "- Use appropriate evaluation metrics\n",
    "- Multiple horizons\n",
    "- Density forecasts when possible\n",
    "- Model averaging\n",
    "\n",
    "**Interpretation**:\n",
    "- Connect to economic theory\n",
    "- Understand limitations\n",
    "- Uncertainty quantification\n",
    "- Sensitivity analysis\n",
    "\n",
    "### 5.4 Advanced Topics and Extensions\n",
    "\n",
    "**Machine Learning Integration**:\n",
    "- Neural networks for forecasting\n",
    "- Regularized TVP-VAR (LASSO, Ridge)\n",
    "- Tree-based methods\n",
    "- Ensemble approaches\n",
    "\n",
    "**High-Frequency Data**:\n",
    "- Realized measures\n",
    "- Microstructure effects\n",
    "- HAR models\n",
    "- Continuous-time methods\n",
    "\n",
    "**Mixed-Frequency Models**:\n",
    "- MIDAS regression\n",
    "- State space with mixed frequencies\n",
    "- Nowcasting\n",
    "\n",
    "**Factor Models**:\n",
    "- Dynamic factor models\n",
    "- Factor-augmented VAR\n",
    "- Big data applications\n",
    "\n",
    "**Non-Gaussian Methods**:\n",
    "- Quantile regression\n",
    "- Copula models\n",
    "- Extreme value theory\n",
    "\n",
    "### 5.5 Software and Resources\n",
    "\n",
    "**Python**:\n",
    "- statsmodels: Standard time series\n",
    "- arch: GARCH models\n",
    "- PyMC: Bayesian estimation\n",
    "- scikit-learn: ML integration\n",
    "\n",
    "**R**:\n",
    "- vars: VAR/VECM\n",
    "- rugarch: GARCH\n",
    "- bvartools: Bayesian VAR\n",
    "- MSBVAR: TVP-VAR\n",
    "\n",
    "**MATLAB**:\n",
    "- Econometrics Toolbox\n",
    "- Bear Toolbox (TVP-VAR)\n",
    "- RISE Toolbox\n",
    "\n",
    "**Commercial**:\n",
    "- EViews\n",
    "- RATS\n",
    "- Ox/PcGive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Exercises\n",
    "\n",
    "### Exercise 1: Complete TVP-VAR Analysis\n",
    "For a trivariate system of your choice:\n",
    "1. Estimate constant-parameter VAR\n",
    "2. Test for parameter stability\n",
    "3. Estimate rolling window VAR\n",
    "4. Calculate time-varying IRFs\n",
    "5. Compare crisis vs normal dynamics\n",
    "6. Economic interpretation\n",
    "\n",
    "### Exercise 2: Spillover Analysis\n",
    "For international stock markets:\n",
    "1. Download data for US, Europe, Asia\n",
    "2. Calculate rolling VAR\n",
    "3. Compute spillover index over time\n",
    "4. Identify net transmitters vs receivers\n",
    "5. How does connectedness evolve?\n",
    "6. Link to major events\n",
    "\n",
    "### Exercise 3: Crisis Detection\n",
    "Use TVP-VAR to detect crises:\n",
    "1. Estimate TVP-VAR on financial data\n",
    "2. Track changes in parameters\n",
    "3. Identify rapid changes\n",
    "4. Compare with known crisis dates\n",
    "5. Early warning indicators?\n",
    "\n",
    "### Exercise 4: Forecasting Horse Race\n",
    "Compare forecasting methods:\n",
    "1. ARIMA (univariate)\n",
    "2. VAR (constant parameter)\n",
    "3. VECM (if cointegrated)\n",
    "4. Rolling VAR\n",
    "5. Which performs best? When? Why?\n",
    "\n",
    "### Exercise 5: Integrated Project\n",
    "Complete analysis of a research question:\n",
    "1. Choose economic/financial question\n",
    "2. Apply appropriate methods from course\n",
    "3. Test robustness\n",
    "4. Provide economic interpretation\n",
    "5. Policy/trading implications\n",
    "6. Write brief report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Space for your solutions to exercises\n",
    "\n",
    "# Exercise 1:\n",
    "# Your code here\n",
    "\n",
    "# Exercise 2:\n",
    "# Your code here\n",
    "\n",
    "# Exercise 3:\n",
    "# Your code here\n",
    "\n",
    "# Exercise 4:\n",
    "# Your code here\n",
    "\n",
    "# Exercise 5:\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Further Reading\n",
    "\n",
    "### Seminal Papers:\n",
    "1. Primiceri, G.E. (2005). Time varying structural vector autoregressions and monetary policy. *Review of Economic Studies*, 72(3), 821-852.\n",
    "2. Cogley, T., & Sargent, T.J. (2005). Drifts and volatilities: Monetary policies and outcomes in the post WWII US. *Review of Economic Dynamics*, 8(2), 262-302.\n",
    "3. Diebold, F.X., & Yilmaz, K. (2009). Measuring financial asset return and volatility spillovers. *Economic Journal*, 119(534), 158-171.\n",
    "4. Diebold, F.X., & Yilmaz, K. (2014). On the network topology of variance decompositions. *Journal of Econometrics*, 182(1), 119-134.\n",
    "\n",
    "### Textbooks:\n",
    "1. Koop, G., & Korobilis, D. (2010). Bayesian multivariate time series methods for empirical macroeconomics. *Foundations and Trends in Econometrics*, 3(4), 267-358.\n",
    "2. Chan, J.C., Koop, G., Poirier, D.J., & Tobias, J.L. (2019). *Bayesian Econometric Methods* (2nd ed.). Cambridge University Press.\n",
    "3. Durbin, J., & Koopman, S.J. (2012). *Time Series Analysis by State Space Methods* (2nd ed.). Oxford University Press.\n",
    "\n",
    "### Applied Papers:\n",
    "1. Koop, G., Leon-Gonzalez, R., & Strachan, R.W. (2009). On the evolution of the monetary policy transmission mechanism. *Journal of Economic Dynamics and Control*, 33(4), 997-1017.\n",
    "2. Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. *Journal of Applied Econometrics*, 25(1), 71-92.\n",
    "3. Caggiano, G., Castelnuovo, E., & Groshenny, N. (2014). Uncertainty shocks and unemployment dynamics. *Journal of Monetary Economics*, 67, 78-92.\n",
    "\n",
    "### Software and Implementations:\n",
    "1. BEAR Toolbox (MATLAB): https://github.com/european-central-bank/BEAR-toolbox\n",
    "2. bvartools (R): https://cran.r-project.org/package=bvartools\n",
    "3. PyMC: https://www.pymc.io/\n",
    "4. Stan: https://mc-stan.org/\n",
    "\n",
    "### Online Resources:\n",
    "1. Diebold-Yilmaz Connectedness: https://www.connectednessnetwork.com/\n",
    "2. Koop's Lecture Notes: http://personal.strath.ac.uk/gary.koop/\n",
    "3. ECB Working Papers: https://www.ecb.europa.eu/\n",
    "\n",
    "---\n",
    "\n",
    "**Instructor Contact**: [Mathis J.F. Mourey. mjfmourey@hhs.nl]\n",
    "\n",
    "**Office Hours**: [Mon-Fri 9am-5pm]\n",
    "\n",
    "---\n",
    "\n",
    "# End of Summer School: Time Series Methods for Finance and Economics\n",
    "\n",
    "## Thank you for participating!\n",
    "\n",
    "**Course Summary**:\n",
    "- 11 comprehensive sessions\n",
    "- From univariate ARIMA to TVP-VAR\n",
    "- Theory, implementation, and applications\n",
    "- Real financial and economic data\n",
    "- Production-ready code\n",
    "\n",
    "**What's next?**\n",
    "- Practice with your own data\n",
    "- Read papers using these methods\n",
    "- Contribute to open-source implementations\n",
    "- Apply to research and industry\n",
    "- Stay updated with new developments\n",
    "\n",
    "**Good luck with your time series projects!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}