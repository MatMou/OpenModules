{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 10: Capstone Project and Case Studies\n",
    "\n",
    "## Event Studies in Finance and Economics - Summer School\n",
    "\n",
    "---\n",
    "\n",
    "### Session Overview\n",
    "\n",
    "This final session brings together everything we've learned through:\n",
    "\n",
    "1. **Three complete case studies** demonstrating different event study applications\n",
    "2. **A comprehensive reusable toolkit** consolidating all methods\n",
    "3. **Guided capstone project** with real data\n",
    "4. **Course summary** and further reading\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Complete Event Study Toolkit\n",
    "\n",
    "We begin by loading a comprehensive toolkit that integrates all methods from previous sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import yfinance as yf\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple, Union, Callable\n",
    "from enum import Enum\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EVENT STUDY TOOLKIT - SUMMER SCHOOL CAPSTONE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE EVENT STUDY TOOLKIT\n",
    "# ============================================================================\n",
    "\n",
    "class ExpectedReturnModel(Enum):\n",
    "    MARKET_MODEL = \"market_model\"\n",
    "    MARKET_ADJUSTED = \"market_adjusted\"\n",
    "    MEAN_ADJUSTED = \"mean_adjusted\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EventStudyConfig:\n",
    "    \"\"\"Configuration for event study.\"\"\"\n",
    "    estimation_window: int = 120\n",
    "    gap: int = 10\n",
    "    event_window_pre: int = 5\n",
    "    event_window_post: int = 5\n",
    "    expected_return_model: ExpectedReturnModel = ExpectedReturnModel.MARKET_MODEL\n",
    "    min_estimation_obs: int = 60\n",
    "    market_index: str = \"^GSPC\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EventResult:\n",
    "    \"\"\"Results for a single event.\"\"\"\n",
    "    ticker: str\n",
    "    event_date: pd.Timestamp\n",
    "    event_data: pd.DataFrame\n",
    "    alpha: float\n",
    "    beta: float\n",
    "    sigma: float\n",
    "    r_squared: float\n",
    "    n_est: int\n",
    "    valid: bool = True\n",
    "    error: str = \"\"\n",
    "    metadata: Dict = field(default_factory=dict)\n",
    "    \n",
    "    def car(self, t1: int, t2: int) -> float:\n",
    "        mask = (self.event_data['t'] >= t1) & (self.event_data['t'] <= t2)\n",
    "        return self.event_data.loc[mask, 'AR'].sum()\n",
    "    \n",
    "    def scar(self, t1: int, t2: int) -> float:\n",
    "        L = len(self.event_data[(self.event_data['t'] >= t1) & (self.event_data['t'] <= t2)])\n",
    "        var = L * self.sigma ** 2\n",
    "        return self.car(t1, t2) / np.sqrt(var) if var > 0 else np.nan\n",
    "\n",
    "\n",
    "class EventStudyToolkit:\n",
    "    \"\"\"\n",
    "    Complete event study toolkit consolidating all course methods.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: EventStudyConfig = None):\n",
    "        self.config = config or EventStudyConfig()\n",
    "        self._cache = {}\n",
    "    \n",
    "    # ==================== DATA METHODS ====================\n",
    "    \n",
    "    def download_data(self, ticker: str, start: str, end: str) -> pd.Series:\n",
    "        \"\"\"Download and cache price data.\"\"\"\n",
    "        key = (ticker, start, end)\n",
    "        if key not in self._cache:\n",
    "            data = yf.download(ticker, start=start, end=end, progress=False)['Adj Close']\n",
    "            self._cache[key] = data.squeeze().pct_change().dropna()\n",
    "        return self._cache[key]\n",
    "    \n",
    "    # ==================== ESTIMATION METHODS ====================\n",
    "    \n",
    "    def estimate_market_model(self, stock_ret: pd.Series, \n",
    "                               market_ret: pd.Series) -> Tuple[float, float, float, float]:\n",
    "        \"\"\"Estimate market model: R_i = alpha + beta * R_m + epsilon.\"\"\"\n",
    "        common = stock_ret.index.intersection(market_ret.index)\n",
    "        y, x = stock_ret.loc[common], market_ret.loc[common]\n",
    "        X = sm.add_constant(x)\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        return model.params.iloc[0], model.params.iloc[1], np.std(model.resid, ddof=2), model.rsquared\n",
    "    \n",
    "    # ==================== CORE EVENT STUDY ====================\n",
    "    \n",
    "    def process_event(self, ticker: str, event_date: str, \n",
    "                       metadata: Dict = None) -> EventResult:\n",
    "        \"\"\"Process a single event.\"\"\"\n",
    "        try:\n",
    "            event_dt = pd.to_datetime(event_date)\n",
    "            cfg = self.config\n",
    "            \n",
    "            # Date range\n",
    "            total_pre = cfg.estimation_window + cfg.gap + cfg.event_window_pre\n",
    "            start = event_dt - timedelta(days=int(total_pre * 1.5))\n",
    "            end = event_dt + timedelta(days=int(cfg.event_window_post * 2.5))\n",
    "            \n",
    "            # Download data\n",
    "            stock = self.download_data(ticker, start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))\n",
    "            market = self.download_data(cfg.market_index, start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))\n",
    "            \n",
    "            # Align\n",
    "            common = stock.index.intersection(market.index)\n",
    "            df = pd.DataFrame({'stock': stock.loc[common], 'market': market.loc[common]})\n",
    "            \n",
    "            # Find event date\n",
    "            if event_dt not in df.index:\n",
    "                idx = df.index.get_indexer([event_dt], method='nearest')[0]\n",
    "                event_dt = df.index[idx]\n",
    "            \n",
    "            event_idx = df.index.get_loc(event_dt)\n",
    "            df['t'] = range(-event_idx, len(df) - event_idx)\n",
    "            \n",
    "            # Split periods\n",
    "            est_end = -(cfg.gap + cfg.event_window_pre)\n",
    "            est_mask = (df['t'] >= est_end - cfg.estimation_window) & (df['t'] < est_end)\n",
    "            evt_mask = (df['t'] >= -cfg.event_window_pre) & (df['t'] <= cfg.event_window_post)\n",
    "            \n",
    "            est_data = df[est_mask]\n",
    "            evt_data = df[evt_mask].copy()\n",
    "            \n",
    "            if len(est_data) < cfg.min_estimation_obs:\n",
    "                raise ValueError(f\"Insufficient estimation data: {len(est_data)}\")\n",
    "            \n",
    "            # Estimate model\n",
    "            if cfg.expected_return_model == ExpectedReturnModel.MARKET_MODEL:\n",
    "                alpha, beta, sigma, r2 = self.estimate_market_model(est_data['stock'], est_data['market'])\n",
    "                evt_data['ER'] = alpha + beta * evt_data['market']\n",
    "            elif cfg.expected_return_model == ExpectedReturnModel.MARKET_ADJUSTED:\n",
    "                alpha, beta, sigma, r2 = 0, 1, est_data['stock'].std(), 0\n",
    "                evt_data['ER'] = evt_data['market']\n",
    "            else:  # MEAN_ADJUSTED\n",
    "                alpha = est_data['stock'].mean()\n",
    "                beta, sigma, r2 = 0, est_data['stock'].std(), 0\n",
    "                evt_data['ER'] = alpha\n",
    "            \n",
    "            evt_data['AR'] = evt_data['stock'] - evt_data['ER']\n",
    "            evt_data['CAR'] = evt_data['AR'].cumsum()\n",
    "            \n",
    "            return EventResult(\n",
    "                ticker=ticker, event_date=event_dt, event_data=evt_data,\n",
    "                alpha=alpha, beta=beta, sigma=sigma, r_squared=r2,\n",
    "                n_est=len(est_data), metadata=metadata or {}\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            return EventResult(\n",
    "                ticker=ticker, event_date=pd.to_datetime(event_date),\n",
    "                event_data=None, alpha=0, beta=0, sigma=0, r_squared=0,\n",
    "                n_est=0, valid=False, error=str(e)\n",
    "            )\n",
    "    \n",
    "    def process_events(self, events: List[Dict], verbose: bool = True) -> List[EventResult]:\n",
    "        \"\"\"Process multiple events.\"\"\"\n",
    "        results = []\n",
    "        for i, e in enumerate(events):\n",
    "            if verbose:\n",
    "                print(f\"  [{i+1}/{len(events)}] {e['ticker']}...\", end=\" \")\n",
    "            result = self.process_event(e['ticker'], e['date'], e.get('metadata', {}))\n",
    "            results.append(result)\n",
    "            if verbose:\n",
    "                print(\"OK\" if result.valid else f\"FAILED: {result.error}\")\n",
    "        return results\n",
    "    \n",
    "    # ==================== STATISTICAL TESTS ====================\n",
    "    \n",
    "    def cross_sectional_test(self, results: List[EventResult], t1: int, t2: int) -> Dict:\n",
    "        \"\"\"Cross-sectional t-test on CARs.\"\"\"\n",
    "        cars = np.array([r.car(t1, t2) for r in results if r.valid])\n",
    "        n = len(cars)\n",
    "        mean = np.mean(cars)\n",
    "        std = np.std(cars, ddof=1)\n",
    "        t_stat = mean / (std / np.sqrt(n)) if std > 0 else 0\n",
    "        p_val = 2 * (1 - stats.t.cdf(abs(t_stat), df=n-1))\n",
    "        return {'caar': mean, 'std': std, 't': t_stat, 'p': p_val, 'n': n, 'cars': cars}\n",
    "    \n",
    "    def patell_test(self, results: List[EventResult], t1: int, t2: int) -> Dict:\n",
    "        \"\"\"Patell (1976) standardized residual test.\"\"\"\n",
    "        scars = np.array([r.scar(t1, t2) for r in results if r.valid])\n",
    "        scars = scars[~np.isnan(scars)]\n",
    "        n = len(scars)\n",
    "        z = np.sum(scars) / np.sqrt(n) if n > 0 else 0\n",
    "        p = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "        return {'z': z, 'p': p, 'n': n}\n",
    "    \n",
    "    def bmp_test(self, results: List[EventResult], t1: int, t2: int) -> Dict:\n",
    "        \"\"\"Boehmer-Musumeci-Poulsen (1991) test.\"\"\"\n",
    "        scars = np.array([r.scar(t1, t2) for r in results if r.valid])\n",
    "        scars = scars[~np.isnan(scars)]\n",
    "        n = len(scars)\n",
    "        mean_s = np.mean(scars)\n",
    "        std_s = np.std(scars, ddof=1)\n",
    "        t_stat = mean_s / (std_s / np.sqrt(n)) if std_s > 0 else 0\n",
    "        p = 2 * (1 - stats.t.cdf(abs(t_stat), df=n-1))\n",
    "        return {'t': t_stat, 'p': p, 'n': n}\n",
    "    \n",
    "    def sign_test(self, results: List[EventResult], t1: int, t2: int) -> Dict:\n",
    "        \"\"\"Non-parametric sign test.\"\"\"\n",
    "        cars = np.array([r.car(t1, t2) for r in results if r.valid])\n",
    "        n_pos = np.sum(cars > 0)\n",
    "        n = len(cars)\n",
    "        z = (n_pos - 0.5*n) / np.sqrt(0.25*n)\n",
    "        p = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "        return {'n_pos': n_pos, 'pct_pos': n_pos/n*100, 'z': z, 'p': p, 'n': n}\n",
    "    \n",
    "    def rank_test(self, results: List[EventResult], t1: int, t2: int) -> Dict:\n",
    "        \"\"\"Corrado (1989) rank test.\"\"\"\n",
    "        valid = [r for r in results if r.valid]\n",
    "        K_avg = []\n",
    "        for r in valid:\n",
    "            mask = (r.event_data['t'] >= t1) & (r.event_data['t'] <= t2)\n",
    "            ar_event = r.event_data.loc[mask, 'AR'].values\n",
    "            # Simple approximation using event window ranks\n",
    "            ranks = stats.rankdata(ar_event)\n",
    "            T = len(ar_event)\n",
    "            K = ranks / (T + 1) - 0.5\n",
    "            K_avg.append(np.mean(K))\n",
    "        \n",
    "        K_avg = np.array(K_avg)\n",
    "        n = len(K_avg)\n",
    "        mean_K = np.mean(K_avg)\n",
    "        std_K = np.std(K_avg, ddof=1)\n",
    "        z = mean_K / (std_K / np.sqrt(n)) if std_K > 0 else 0\n",
    "        p = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "        return {'z': z, 'p': p, 'n': n}\n",
    "    \n",
    "    def bootstrap_test(self, results: List[EventResult], t1: int, t2: int, \n",
    "                        n_boot: int = 5000) -> Dict:\n",
    "        \"\"\"Bootstrap confidence interval.\"\"\"\n",
    "        cars = np.array([r.car(t1, t2) for r in results if r.valid])\n",
    "        n = len(cars)\n",
    "        observed = np.mean(cars)\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        boot = np.array([np.mean(np.random.choice(cars, n, replace=True)) for _ in range(n_boot)])\n",
    "        \n",
    "        ci = np.percentile(boot, [2.5, 97.5])\n",
    "        p = np.mean(np.abs(boot - observed) >= np.abs(observed))\n",
    "        \n",
    "        return {'caar': observed, 'ci_low': ci[0], 'ci_high': ci[1], 'se': np.std(boot), 'p': p, 'n': n}\n",
    "    \n",
    "    # ==================== ANALYSIS ====================\n",
    "    \n",
    "    def comprehensive_analysis(self, results: List[EventResult],\n",
    "                                windows: List[Tuple[int, int]] = None) -> pd.DataFrame:\n",
    "        \"\"\"Run all tests for multiple windows.\"\"\"\n",
    "        if windows is None:\n",
    "            windows = [(-1, 1), (0, 0), (-5, 5), (0, 5)]\n",
    "        \n",
    "        rows = []\n",
    "        for t1, t2 in windows:\n",
    "            cs = self.cross_sectional_test(results, t1, t2)\n",
    "            pt = self.patell_test(results, t1, t2)\n",
    "            bmp = self.bmp_test(results, t1, t2)\n",
    "            sign = self.sign_test(results, t1, t2)\n",
    "            rank = self.rank_test(results, t1, t2)\n",
    "            \n",
    "            rows.append({\n",
    "                'Window': f\"({t1},{t2})\",\n",
    "                'N': cs['n'],\n",
    "                'CAAR': cs['caar'],\n",
    "                'Median': np.median(cs['cars']),\n",
    "                't-stat': cs['t'],\n",
    "                'Patell-z': pt['z'],\n",
    "                'BMP-t': bmp['t'],\n",
    "                'Sign-z': sign['z'],\n",
    "                'Rank-z': rank['z'],\n",
    "                '%Pos': sign['pct_pos'],\n",
    "                'p-value': cs['p']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(rows)\n",
    "    \n",
    "    def get_time_series(self, results: List[EventResult]) -> pd.DataFrame:\n",
    "        \"\"\"Calculate AAR and CAAR time series.\"\"\"\n",
    "        valid = [r for r in results if r.valid]\n",
    "        all_t = sorted(set(t for r in valid for t in r.event_data['t'].values))\n",
    "        \n",
    "        rows = []\n",
    "        for t in all_t:\n",
    "            ars = [r.event_data[r.event_data['t'] == t]['AR'].values[0] \n",
    "                   for r in valid if t in r.event_data['t'].values]\n",
    "            if ars:\n",
    "                rows.append({'t': t, 'AAR': np.mean(ars), 'AAR_se': np.std(ars, ddof=1)/np.sqrt(len(ars)), 'n': len(ars)})\n",
    "        \n",
    "        df = pd.DataFrame(rows)\n",
    "        df['CAAR'] = df['AAR'].cumsum()\n",
    "        return df\n",
    "    \n",
    "    # ==================== VISUALIZATION ====================\n",
    "    \n",
    "    def plot_caar(self, results: List[EventResult], ax=None, title: str = None):\n",
    "        \"\"\"Plot CAAR with confidence bands.\"\"\"\n",
    "        ts = self.get_time_series(results)\n",
    "        \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        ax.plot(ts['t'], ts['CAAR']*100, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "        cum_se = ts['AAR_se'].cumsum()\n",
    "        ax.fill_between(ts['t'], (ts['CAAR']-1.96*cum_se)*100, (ts['CAAR']+1.96*cum_se)*100, alpha=0.2)\n",
    "        ax.axhline(0, color='gray', linewidth=0.5)\n",
    "        ax.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "        ax.set_xlabel('Event Time')\n",
    "        ax.set_ylabel('CAAR (%)')\n",
    "        ax.set_title(title or 'Cumulative Average Abnormal Return')\n",
    "        return ax\n",
    "    \n",
    "    def plot_car_distribution(self, results: List[EventResult], t1: int, t2: int, ax=None):\n",
    "        \"\"\"Plot CAR distribution.\"\"\"\n",
    "        cars = [r.car(t1, t2)*100 for r in results if r.valid]\n",
    "        \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        \n",
    "        ax.hist(cars, bins=15, edgecolor='black', alpha=0.7)\n",
    "        ax.axvline(np.mean(cars), color='red', linestyle='--', linewidth=2, label=f'Mean={np.mean(cars):.2f}%')\n",
    "        ax.axvline(0, color='black', linewidth=1)\n",
    "        ax.set_xlabel(f'CAR({t1},{t2}) %')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.legend()\n",
    "        return ax\n",
    "\n",
    "\n",
    "print(\"EventStudyToolkit loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study 1: Earnings Announcements\n",
    "\n",
    "### Research Question\n",
    "\n",
    "**Do earnings announcements with positive surprises generate positive abnormal returns?**\n",
    "\n",
    "This is a classic event study application testing semi-strong form market efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Case Study 1: Earnings Announcements\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CASE STUDY 1: EARNINGS ANNOUNCEMENT EFFECTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sample: Q2-Q3 2023 earnings with surprise data\n",
    "earnings_events = [\n",
    "    # Positive surprises\n",
    "    {'ticker': 'NVDA', 'date': '2023-08-23', 'metadata': {'surprise': 0.35, 'type': 'positive'}},\n",
    "    {'ticker': 'META', 'date': '2023-07-26', 'metadata': {'surprise': 0.22, 'type': 'positive'}},\n",
    "    {'ticker': 'AMZN', 'date': '2023-08-03', 'metadata': {'surprise': 0.45, 'type': 'positive'}},\n",
    "    {'ticker': 'GOOGL', 'date': '2023-07-25', 'metadata': {'surprise': 0.12, 'type': 'positive'}},\n",
    "    {'ticker': 'MSFT', 'date': '2023-07-25', 'metadata': {'surprise': 0.08, 'type': 'positive'}},\n",
    "    {'ticker': 'AAPL', 'date': '2023-08-03', 'metadata': {'surprise': 0.05, 'type': 'positive'}},\n",
    "    {'ticker': 'JPM', 'date': '2023-07-14', 'metadata': {'surprise': 0.10, 'type': 'positive'}},\n",
    "    {'ticker': 'WMT', 'date': '2023-08-17', 'metadata': {'surprise': 0.09, 'type': 'positive'}},\n",
    "    # Negative/mixed surprises\n",
    "    {'ticker': 'TSLA', 'date': '2023-07-19', 'metadata': {'surprise': -0.05, 'type': 'negative'}},\n",
    "    {'ticker': 'GS', 'date': '2023-07-19', 'metadata': {'surprise': -0.15, 'type': 'negative'}},\n",
    "    {'ticker': 'AMD', 'date': '2023-08-01', 'metadata': {'surprise': -0.02, 'type': 'negative'}},\n",
    "    {'ticker': 'INTC', 'date': '2023-07-27', 'metadata': {'surprise': 0.18, 'type': 'positive'}},\n",
    "]\n",
    "\n",
    "# Configure and run\n",
    "config = EventStudyConfig(\n",
    "    estimation_window=120,\n",
    "    gap=10,\n",
    "    event_window_pre=5,\n",
    "    event_window_post=5\n",
    ")\n",
    "\n",
    "toolkit = EventStudyToolkit(config)\n",
    "print(\"\\nProcessing earnings events...\")\n",
    "earnings_results = toolkit.process_events(earnings_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Full sample analysis\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"FULL SAMPLE RESULTS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "analysis = toolkit.comprehensive_analysis(earnings_results)\n",
    "\n",
    "def sig(val):\n",
    "    if abs(val) > 2.58: return '***'\n",
    "    if abs(val) > 1.96: return '**'\n",
    "    if abs(val) > 1.65: return '*'\n",
    "    return ''\n",
    "\n",
    "print(f\"\\n{'Window':<10} {'N':>4} {'CAAR':>10} {'Median':>10} {'t-stat':>10} {'Patell':>10} {'%Pos':>8}\")\n",
    "print(\"-\"*70)\n",
    "for _, row in analysis.iterrows():\n",
    "    print(f\"{row['Window']:<10} {int(row['N']):>4} {row['CAAR']*100:>+9.2f}% {row['Median']*100:>+9.2f}% \"\n",
    "          f\"{row['t-stat']:>8.2f}{sig(row['t-stat']):<2} {row['Patell-z']:>8.2f}{sig(row['Patell-z']):<2} \"\n",
    "          f\"{row['%Pos']:>7.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Subsample analysis: Positive vs Negative surprises\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SUBSAMPLE ANALYSIS: POSITIVE vs NEGATIVE SURPRISES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "pos_results = [r for r in earnings_results if r.valid and r.metadata.get('type') == 'positive']\n",
    "neg_results = [r for r in earnings_results if r.valid and r.metadata.get('type') == 'negative']\n",
    "\n",
    "print(f\"\\nPositive Surprises (N={len(pos_results)}):\")\n",
    "if pos_results:\n",
    "    pos_test = toolkit.cross_sectional_test(pos_results, -1, 1)\n",
    "    print(f\"  CAAR(-1,+1) = {pos_test['caar']*100:+.2f}% (t = {pos_test['t']:.2f})\")\n",
    "\n",
    "print(f\"\\nNegative Surprises (N={len(neg_results)}):\")\n",
    "if neg_results:\n",
    "    neg_test = toolkit.cross_sectional_test(neg_results, -1, 1)\n",
    "    print(f\"  CAAR(-1,+1) = {neg_test['caar']*100:+.2f}% (t = {neg_test['t']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# CAAR plot\n",
    "toolkit.plot_caar(earnings_results, ax=axes[0, 0], title='CAAR: Earnings Announcements')\n",
    "\n",
    "# CAR distribution\n",
    "toolkit.plot_car_distribution(earnings_results, -1, 1, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('CAR(-1,+1) Distribution')\n",
    "\n",
    "# CAR vs Surprise scatter\n",
    "ax3 = axes[1, 0]\n",
    "surprises = [r.metadata.get('surprise', 0) for r in earnings_results if r.valid]\n",
    "cars = [r.car(-1, 1)*100 for r in earnings_results if r.valid]\n",
    "colors = ['green' if s > 0 else 'red' for s in surprises]\n",
    "ax3.scatter(surprises, cars, c=colors, s=100, alpha=0.7)\n",
    "\n",
    "# Regression line\n",
    "z = np.polyfit(surprises, cars, 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(min(surprises), max(surprises), 100)\n",
    "ax3.plot(x_line, p(x_line), 'b--', linewidth=2)\n",
    "\n",
    "ax3.axhline(0, color='gray', linewidth=0.5)\n",
    "ax3.axvline(0, color='gray', linewidth=0.5)\n",
    "ax3.set_xlabel('Earnings Surprise')\n",
    "ax3.set_ylabel('CAR(-1,+1) %')\n",
    "ax3.set_title('Earnings Response Coefficient')\n",
    "\n",
    "# Individual firm bars\n",
    "ax4 = axes[1, 1]\n",
    "valid = [r for r in earnings_results if r.valid]\n",
    "tickers = [r.ticker for r in valid]\n",
    "firm_cars = [r.car(-1, 1)*100 for r in valid]\n",
    "colors = ['green' if c > 0 else 'red' for c in firm_cars]\n",
    "ax4.barh(range(len(tickers)), firm_cars, color=colors, alpha=0.7)\n",
    "ax4.set_yticks(range(len(tickers)))\n",
    "ax4.set_yticklabels(tickers)\n",
    "ax4.axvline(0, color='black', linewidth=0.5)\n",
    "ax4.set_xlabel('CAR(-1,+1) %')\n",
    "ax4.set_title('Individual Firm CARs')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cross-sectional regression\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"CROSS-SECTIONAL REGRESSION: CAR on Surprise\")\n",
    "print(\"-\"*80)\n",
    "y = np.array(cars)\n",
    "X = sm.add_constant(np.array(surprises))\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(f\"\\nCAR(-1,+1) = {model.params[0]:.4f} + {model.params[1]:.4f} × Surprise\")\n",
    "print(f\"            ({model.tvalues[0]:.2f})   ({model.tvalues[1]:.2f})\")\n",
    "print(f\"R² = {model.rsquared:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study 2: M&A Announcements\n",
    "\n",
    "### Research Question\n",
    "\n",
    "**How do target and acquirer stock prices react to M&A announcements?**\n",
    "\n",
    "Classic finding: Targets gain, acquirers break even or lose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Case Study 2: M&A Announcements\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CASE STUDY 2: M&A ANNOUNCEMENT EFFECTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sample: Recent tech M&A (using acquirer stocks where target was acquired)\n",
    "# Using acquirers since targets often delist\n",
    "ma_events = [\n",
    "    # Major tech acquisitions (acquirer perspective)\n",
    "    {'ticker': 'MSFT', 'date': '2022-01-18', 'metadata': {'role': 'acquirer', 'target': 'Activision', 'value': 69}},\n",
    "    {'ticker': 'AVGO', 'date': '2023-05-26', 'metadata': {'role': 'acquirer', 'target': 'VMware', 'value': 61}},\n",
    "    {'ticker': 'AMZN', 'date': '2022-03-17', 'metadata': {'role': 'acquirer', 'target': 'MGM', 'value': 8.5}},\n",
    "    {'ticker': 'META', 'date': '2021-10-28', 'metadata': {'role': 'acquirer', 'target': 'Within', 'value': 0.4}},\n",
    "    {'ticker': 'GOOGL', 'date': '2022-03-15', 'metadata': {'role': 'acquirer', 'target': 'Mandiant', 'value': 5.4}},\n",
    "    {'ticker': 'CRM', 'date': '2020-12-01', 'metadata': {'role': 'acquirer', 'target': 'Slack', 'value': 27.7}},\n",
    "    {'ticker': 'AMD', 'date': '2020-10-27', 'metadata': {'role': 'acquirer', 'target': 'Xilinx', 'value': 35}},\n",
    "    {'ticker': 'NVDA', 'date': '2020-09-13', 'metadata': {'role': 'acquirer', 'target': 'ARM', 'value': 40}},\n",
    "]\n",
    "\n",
    "# Process M&A events\n",
    "ma_config = EventStudyConfig(\n",
    "    estimation_window=120,\n",
    "    gap=10,\n",
    "    event_window_pre=10,\n",
    "    event_window_post=10\n",
    ")\n",
    "\n",
    "ma_toolkit = EventStudyToolkit(ma_config)\n",
    "print(\"\\nProcessing M&A events...\")\n",
    "ma_results = ma_toolkit.process_events(ma_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# M&A Results\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"M&A ANNOUNCEMENT RESULTS (ACQUIRER RETURNS)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "ma_analysis = ma_toolkit.comprehensive_analysis(ma_results, windows=[(-1, 1), (-3, 3), (-5, 5), (-10, 10)])\n",
    "\n",
    "print(f\"\\n{'Window':<12} {'N':>4} {'CAAR':>10} {'t-stat':>10} {'%Pos':>8}\")\n",
    "print(\"-\"*50)\n",
    "for _, row in ma_analysis.iterrows():\n",
    "    print(f\"{row['Window']:<12} {int(row['N']):>4} {row['CAAR']*100:>+9.2f}% \"\n",
    "          f\"{row['t-stat']:>8.2f}{sig(row['t-stat']):<2} {row['%Pos']:>7.0f}%\")\n",
    "\n",
    "print(\"\\nNote: Acquirers typically show zero or negative CARs at announcement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# M&A Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# CAAR plot\n",
    "ma_toolkit.plot_caar(ma_results, ax=axes[0], title='Acquirer CAAR: M&A Announcements')\n",
    "\n",
    "# Deal value vs CAR\n",
    "ax2 = axes[1]\n",
    "valid_ma = [r for r in ma_results if r.valid]\n",
    "values = [r.metadata.get('value', 0) for r in valid_ma]\n",
    "ma_cars = [r.car(-1, 1)*100 for r in valid_ma]\n",
    "tickers = [r.ticker for r in valid_ma]\n",
    "\n",
    "ax2.scatter(values, ma_cars, s=150, alpha=0.7)\n",
    "for i, ticker in enumerate(tickers):\n",
    "    ax2.annotate(ticker, (values[i], ma_cars[i]), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "ax2.axhline(0, color='gray', linewidth=0.5)\n",
    "ax2.set_xlabel('Deal Value ($B)')\n",
    "ax2.set_ylabel('CAR(-1,+1) %')\n",
    "ax2.set_title('Acquirer CAR vs Deal Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study 3: Regulatory/Policy Events\n",
    "\n",
    "### Research Question\n",
    "\n",
    "**How do industry stocks react to major regulatory announcements?**\n",
    "\n",
    "Example: Fed interest rate decisions affect financial stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Case Study 3: Fed Rate Decisions - Bank Stock Reactions\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CASE STUDY 3: FED RATE DECISION EFFECTS ON BANK STOCKS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 2023 Fed meetings with rate decisions\n",
    "fed_dates = ['2023-02-01', '2023-03-22', '2023-05-03', '2023-06-14', \n",
    "             '2023-07-26', '2023-09-20', '2023-11-01', '2023-12-13']\n",
    "\n",
    "# Bank stocks to analyze\n",
    "banks = ['JPM', 'BAC', 'WFC', 'C', 'GS', 'MS']\n",
    "\n",
    "# Create events: Each bank for each Fed date\n",
    "fed_events = []\n",
    "for date in fed_dates:\n",
    "    for bank in banks:\n",
    "        fed_events.append({'ticker': bank, 'date': date, 'metadata': {'fed_date': date}})\n",
    "\n",
    "# Configure for short window (Fed announcements are precise)\n",
    "fed_config = EventStudyConfig(\n",
    "    estimation_window=100,\n",
    "    gap=5,\n",
    "    event_window_pre=2,\n",
    "    event_window_post=2\n",
    ")\n",
    "\n",
    "fed_toolkit = EventStudyToolkit(fed_config)\n",
    "print(f\"\\nProcessing {len(fed_events)} bank-Fed date combinations...\")\n",
    "fed_results = fed_toolkit.process_events(fed_events, verbose=False)\n",
    "valid_fed = [r for r in fed_results if r.valid]\n",
    "print(f\"Valid observations: {len(valid_fed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Fed Results\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"BANK STOCK RESPONSE TO FED ANNOUNCEMENTS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "fed_analysis = fed_toolkit.comprehensive_analysis(fed_results, windows=[(-1, 1), (0, 0), (0, 1)])\n",
    "\n",
    "print(f\"\\n{'Window':<12} {'N':>4} {'CAAR':>10} {'t-stat':>10} {'Patell':>10} {'%Pos':>8}\")\n",
    "print(\"-\"*60)\n",
    "for _, row in fed_analysis.iterrows():\n",
    "    print(f\"{row['Window']:<12} {int(row['N']):>4} {row['CAAR']*100:>+9.3f}% \"\n",
    "          f\"{row['t-stat']:>8.2f}{sig(row['t-stat']):<2} {row['Patell-z']:>8.2f}{sig(row['Patell-z']):<2} \"\n",
    "          f\"{row['%Pos']:>7.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Analysis by bank\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"RESULTS BY BANK\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "bank_results = {}\n",
    "for bank in banks:\n",
    "    bank_events = [r for r in fed_results if r.valid and r.ticker == bank]\n",
    "    if bank_events:\n",
    "        test = fed_toolkit.cross_sectional_test(bank_events, -1, 1)\n",
    "        bank_results[bank] = test\n",
    "\n",
    "print(f\"\\n{'Bank':<8} {'N':>4} {'CAAR(-1,+1)':>14} {'t-stat':>10}\")\n",
    "print(\"-\"*40)\n",
    "for bank, test in bank_results.items():\n",
    "    print(f\"{bank:<8} {test['n']:>4} {test['caar']*100:>+13.3f}% {test['t']:>8.2f}{sig(test['t'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Fed study visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# CAAR\n",
    "fed_toolkit.plot_caar(fed_results, ax=axes[0], title='Bank Stock CAAR: Fed Announcements')\n",
    "\n",
    "# By bank bar chart\n",
    "ax2 = axes[1]\n",
    "bank_caars = [bank_results[b]['caar']*100 for b in banks if b in bank_results]\n",
    "bank_labels = [b for b in banks if b in bank_results]\n",
    "colors = ['green' if c > 0 else 'red' for c in bank_caars]\n",
    "\n",
    "ax2.bar(bank_labels, bank_caars, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.axhline(0, color='black', linewidth=0.5)\n",
    "ax2.set_ylabel('Average CAR(-1,+1) %')\n",
    "ax2.set_title('Average Response by Bank')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Capstone Project: Your Own Event Study\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Use the toolkit below to conduct your own event study. The template provides:\n",
    "\n",
    "1. **Event definition** - Define your events\n",
    "2. **Configuration** - Set your parameters\n",
    "3. **Processing** - Run the event study\n",
    "4. **Analysis** - Statistical tests\n",
    "5. **Visualization** - Graphs and tables\n",
    "6. **Interpretation** - Draw conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CAPSTONE PROJECT TEMPLATE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CAPSTONE PROJECT: DIVIDEND ANNOUNCEMENT EFFECTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# STEP 1: Define your research question\n",
    "print(\"\"\"\n",
    "RESEARCH QUESTION:\n",
    "Do dividend increase announcements generate positive abnormal returns?\n",
    "\n",
    "HYPOTHESIS:\n",
    "H1: CAAR(-1,+1) > 0 for dividend increase announcements\n",
    "\"\"\")\n",
    "\n",
    "# STEP 2: Define your events\n",
    "# Example: Dividend increase announcements in 2023\n",
    "dividend_events = [\n",
    "    {'ticker': 'AAPL', 'date': '2023-05-04', 'metadata': {'increase_pct': 4.3}},\n",
    "    {'ticker': 'MSFT', 'date': '2023-09-19', 'metadata': {'increase_pct': 10.0}},\n",
    "    {'ticker': 'JPM', 'date': '2023-06-28', 'metadata': {'increase_pct': 5.0}},\n",
    "    {'ticker': 'JNJ', 'date': '2023-04-18', 'metadata': {'increase_pct': 5.3}},\n",
    "    {'ticker': 'PG', 'date': '2023-04-11', 'metadata': {'increase_pct': 3.0}},\n",
    "    {'ticker': 'KO', 'date': '2023-02-16', 'metadata': {'increase_pct': 4.5}},\n",
    "    {'ticker': 'PEP', 'date': '2023-05-02', 'metadata': {'increase_pct': 10.0}},\n",
    "    {'ticker': 'HD', 'date': '2023-02-23', 'metadata': {'increase_pct': 10.0}},\n",
    "    {'ticker': 'MCD', 'date': '2023-10-27', 'metadata': {'increase_pct': 10.0}},\n",
    "    {'ticker': 'V', 'date': '2023-10-24', 'metadata': {'increase_pct': 15.6}},\n",
    "]\n",
    "\n",
    "print(f\"Sample: {len(dividend_events)} dividend increase announcements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# STEP 3: Configure the study\n",
    "div_config = EventStudyConfig(\n",
    "    estimation_window=120,      # 120 trading days\n",
    "    gap=10,                      # 10 day gap\n",
    "    event_window_pre=5,          # 5 days before\n",
    "    event_window_post=5,         # 5 days after\n",
    "    expected_return_model=ExpectedReturnModel.MARKET_MODEL,\n",
    "    min_estimation_obs=60\n",
    ")\n",
    "\n",
    "# STEP 4: Process events\n",
    "div_toolkit = EventStudyToolkit(div_config)\n",
    "print(\"\\nProcessing dividend events...\")\n",
    "div_results = div_toolkit.process_events(dividend_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# STEP 5: Statistical Analysis\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"STATISTICAL RESULTS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "div_analysis = div_toolkit.comprehensive_analysis(div_results)\n",
    "\n",
    "print(f\"\\n{'Window':<10} {'N':>4} {'CAAR':>10} {'Median':>10} {'t-stat':>10} {'BMP':>10} {'%Pos':>8}\")\n",
    "print(\"-\"*70)\n",
    "for _, row in div_analysis.iterrows():\n",
    "    print(f\"{row['Window']:<10} {int(row['N']):>4} {row['CAAR']*100:>+9.3f}% {row['Median']*100:>+9.3f}% \"\n",
    "          f\"{row['t-stat']:>8.2f}{sig(row['t-stat']):<2} {row['BMP-t']:>8.2f}{sig(row['BMP-t']):<2} \"\n",
    "          f\"{row['%Pos']:>7.0f}%\")\n",
    "\n",
    "# Bootstrap for main window\n",
    "boot = div_toolkit.bootstrap_test(div_results, -1, 1)\n",
    "print(f\"\\nBootstrap 95% CI for CAAR(-1,+1): [{boot['ci_low']*100:.3f}%, {boot['ci_high']*100:.3f}%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# STEP 6: Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# CAAR plot\n",
    "div_toolkit.plot_caar(div_results, ax=axes[0, 0], title='CAAR: Dividend Increases')\n",
    "\n",
    "# Distribution\n",
    "div_toolkit.plot_car_distribution(div_results, -1, 1, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('CAR(-1,+1) Distribution')\n",
    "\n",
    "# CAR vs Dividend Increase %\n",
    "ax3 = axes[1, 0]\n",
    "valid_div = [r for r in div_results if r.valid]\n",
    "increases = [r.metadata.get('increase_pct', 0) for r in valid_div]\n",
    "div_cars = [r.car(-1, 1)*100 for r in valid_div]\n",
    "tickers = [r.ticker for r in valid_div]\n",
    "\n",
    "ax3.scatter(increases, div_cars, s=100, alpha=0.7)\n",
    "for i, ticker in enumerate(tickers):\n",
    "    ax3.annotate(ticker, (increases[i], div_cars[i]), xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "# Regression line\n",
    "z = np.polyfit(increases, div_cars, 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(min(increases), max(increases), 100)\n",
    "ax3.plot(x_line, p(x_line), 'r--', linewidth=2)\n",
    "\n",
    "ax3.axhline(0, color='gray', linewidth=0.5)\n",
    "ax3.set_xlabel('Dividend Increase (%)')\n",
    "ax3.set_ylabel('CAR(-1,+1) %')\n",
    "ax3.set_title('CAR vs Dividend Increase Magnitude')\n",
    "\n",
    "# Individual firms\n",
    "ax4 = axes[1, 1]\n",
    "colors = ['green' if c > 0 else 'red' for c in div_cars]\n",
    "ax4.barh(range(len(tickers)), div_cars, color=colors, alpha=0.7)\n",
    "ax4.set_yticks(range(len(tickers)))\n",
    "ax4.set_yticklabels(tickers)\n",
    "ax4.axvline(0, color='black', linewidth=0.5)\n",
    "ax4.set_xlabel('CAR(-1,+1) %')\n",
    "ax4.set_title('Individual Firm CARs')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# STEP 7: Cross-sectional regression\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"CROSS-SECTIONAL ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "y = np.array(div_cars)\n",
    "X = sm.add_constant(np.array(increases))\n",
    "cs_model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(f\"\\nRegression: CAR = α + β × Dividend_Increase\")\n",
    "print(f\"\\n  Intercept (α): {cs_model.params[0]:.4f} (t = {cs_model.tvalues[0]:.2f})\")\n",
    "print(f\"  Slope (β):     {cs_model.params[1]:.4f} (t = {cs_model.tvalues[1]:.2f})\")\n",
    "print(f\"  R-squared:     {cs_model.rsquared:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# STEP 8: Write your conclusions\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "caar_11 = div_toolkit.cross_sectional_test(div_results, -1, 1)\n",
    "sign = div_toolkit.sign_test(div_results, -1, 1)\n",
    "\n",
    "conclusion = f\"\"\"\n",
    "FINDINGS:\n",
    "\n",
    "1. Average Effect:\n",
    "   - CAAR(-1,+1) = {caar_11['caar']*100:+.3f}%\n",
    "   - t-statistic = {caar_11['t']:.2f}\n",
    "   - The average announcement effect is {'statistically significant' if abs(caar_11['t']) > 1.96 else 'not statistically significant'} at the 5% level.\n",
    "\n",
    "2. Sign Test:\n",
    "   - {sign['pct_pos']:.0f}% of events have positive CARs\n",
    "   - This {'supports' if sign['pct_pos'] > 50 else 'does not support'} the hypothesis that dividend increases are viewed positively.\n",
    "\n",
    "3. Cross-Sectional Analysis:\n",
    "   - The relationship between dividend increase magnitude and CAR is {'positive' if cs_model.params[1] > 0 else 'negative'}.\n",
    "   - A 1 percentage point larger dividend increase is associated with a {cs_model.params[1]:.3f}% {'higher' if cs_model.params[1] > 0 else 'lower'} CAR.\n",
    "\n",
    "INTERPRETATION:\n",
    "\n",
    "The results {'support' if caar_11['t'] > 1.65 and caar_11['caar'] > 0 else 'do not strongly support'} the dividend signaling hypothesis.\n",
    "{'Investors appear to interpret dividend increases as positive signals about future cash flows.' if caar_11['t'] > 1.65 and caar_11['caar'] > 0 else 'The market reaction is not conclusively positive, suggesting either efficient pricing or other factors at play.'}\n",
    "\"\"\"\n",
    "\n",
    "print(conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Course Summary\n",
    "\n",
    "### What We Covered\n",
    "\n",
    "| Session | Topic | Key Concepts |\n",
    "|---------|-------|-------------|\n",
    "| 1-2 | Foundations | Market model, estimation windows, event timing |\n",
    "| 3 | Abnormal Returns | AR, CAR, BHAR, aggregation methods |\n",
    "| 4 | Parametric Tests | Cross-sectional t, Patell, BMP, Kolari-Pynnönen |\n",
    "| 5 | Non-parametric Tests | Sign, rank, bootstrap, power analysis |\n",
    "| 6 | Cross-Sectional Analysis | WLS, heteroskedasticity, interactions |\n",
    "| 7 | Long-Horizon Studies | BHAR, calendar-time, clustering |\n",
    "| 8 | Extensions | Intraday, bonds, international, DiD |\n",
    "| 9 | Implementation | Framework design, robustness, pitfalls |\n",
    "| 10 | Capstone | Complete applications, case studies |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Final summary and checklist\n",
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════════╗\n",
    "║                     EVENT STUDY METHODOLOGY SUMMARY                         ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                              ║\n",
    "║  KEY STEPS:                                                                  ║\n",
    "║    1. Define event and identify event dates                                  ║\n",
    "║    2. Collect security and market data                                       ║\n",
    "║    3. Estimate normal returns (market model, FF, etc.)                       ║\n",
    "║    4. Calculate abnormal returns                                             ║\n",
    "║    5. Aggregate across securities                                            ║\n",
    "║    6. Test for significance                                                  ║\n",
    "║    7. Cross-sectional analysis                                               ║\n",
    "║    8. Robustness checks                                                      ║\n",
    "║                                                                              ║\n",
    "║  BEST PRACTICES:                                                             ║\n",
    "║    ✓ Verify event dates from multiple sources                                ║\n",
    "║    ✓ Use multiple test statistics                                            ║\n",
    "║    ✓ Report multiple event windows                                           ║\n",
    "║    ✓ Check robustness to model specification                                 ║\n",
    "║    ✓ Address event clustering                                                ║\n",
    "║    ✓ Consider economic significance                                          ║\n",
    "║                                                                              ║\n",
    "║  COMMON APPLICATIONS:                                                        ║\n",
    "║    • Earnings announcements                                                  ║\n",
    "║    • M&A announcements                                                       ║\n",
    "║    • Dividend changes                                                        ║\n",
    "║    • Stock splits                                                            ║\n",
    "║    • Regulatory/policy changes                                               ║\n",
    "║    • Management changes                                                      ║\n",
    "║    • Credit rating changes                                                   ║\n",
    "║    • Index additions/deletions                                               ║\n",
    "║                                                                              ║\n",
    "╚══════════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Further Reading and Resources\n",
    "\n",
    "### Essential Papers\n",
    "\n",
    "1. **Foundations**\n",
    "   - Fama, E., Fisher, L., Jensen, M., & Roll, R. (1969). The adjustment of stock prices to new information. *International Economic Review*, 10(1), 1-21.\n",
    "   - MacKinlay, A. C. (1997). Event studies in economics and finance. *Journal of Economic Literature*, 35(1), 13-39.\n",
    "\n",
    "2. **Test Statistics**\n",
    "   - Patell, J. M. (1976). Corporate forecasts of earnings per share and stock price behavior: Empirical test. *Journal of Accounting Research*, 14(2), 246-276.\n",
    "   - Boehmer, E., Musumeci, J., & Poulsen, A. (1991). Event-study methodology under conditions of event-induced variance. *Journal of Financial Economics*, 30(2), 253-272.\n",
    "   - Kolari, J. W., & Pynnönen, S. (2010). Event study testing with cross-sectional correlation of abnormal returns. *Review of Financial Studies*, 23(11), 3996-4025.\n",
    "\n",
    "3. **Non-Parametric Methods**\n",
    "   - Corrado, C. J. (1989). A nonparametric test for abnormal security-price performance in event studies. *Journal of Financial Economics*, 23(2), 385-395.\n",
    "   - Cowan, A. R. (1992). Nonparametric event study tests. *Review of Quantitative Finance and Accounting*, 2(4), 343-358.\n",
    "\n",
    "4. **Long-Horizon Studies**\n",
    "   - Barber, B. M., & Lyon, J. D. (1997). Detecting long-run abnormal stock returns: The empirical power and specification of test statistics. *Journal of Financial Economics*, 43(3), 341-372.\n",
    "   - Lyon, J. D., Barber, B. M., & Tsai, C. L. (1999). Improved methods for tests of long-run abnormal stock returns. *Journal of Finance*, 54(1), 165-201.\n",
    "\n",
    "5. **Comprehensive Review**\n",
    "   - Kothari, S. P., & Warner, J. B. (2007). Econometrics of event studies. In *Handbook of Corporate Finance*, Volume 1, 3-36.\n",
    "\n",
    "### Textbooks\n",
    "\n",
    "- Campbell, J. Y., Lo, A. W., & MacKinlay, A. C. (1997). *The Econometrics of Financial Markets*. Princeton University Press.\n",
    "- Benninga, S. (2014). *Financial Modeling*. MIT Press."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════════╗\n",
    "║                                                                              ║\n",
    "║              CONGRATULATIONS ON COMPLETING THE SUMMER SCHOOL!               ║\n",
    "║                                                                              ║\n",
    "║        You now have the tools and knowledge to conduct rigorous             ║\n",
    "║        event studies for academic research and practical applications.      ║\n",
    "║                                                                              ║\n",
    "║        Key Takeaways:                                                        ║\n",
    "║        • Event studies measure market reaction to information               ║\n",
    "║        • Multiple test statistics increase robustness                       ║\n",
    "║        • Design choices matter - be transparent and check robustness        ║\n",
    "║        • Always consider both statistical and economic significance         ║\n",
    "║                                                                              ║\n",
    "║        Good luck with your research!                                        ║\n",
    "║                                                                              ║\n",
    "╚══════════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}